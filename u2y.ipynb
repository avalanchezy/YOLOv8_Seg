{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "from shutil import copy2\n",
    "\n",
    "def resize_and_save_image(image_path, dest_path, scale_dims=(640, 640)):\n",
    "    \"\"\"\n",
    "    Resize an image and save it to the destination path.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image_resized = cv2.resize(image, scale_dims)\n",
    "    cv2.imwrite(str(dest_path), image_resized)\n",
    "\n",
    "def find_significant_points(contour, angle_threshold=30):\n",
    "    \"\"\"\n",
    "    Simplify a contour to include points with significant changes in direction.\n",
    "    \"\"\"\n",
    "    def angle_between(p1, p2, p3):\n",
    "        \"\"\"\n",
    "        Calculate the angle between three points.\n",
    "        \"\"\"\n",
    "        vector1 = p2 - p1\n",
    "        vector2 = p3 - p2\n",
    "        unit_vector1 = vector1 / np.linalg.norm(vector1)\n",
    "        unit_vector2 = vector2 / np.linalg.norm(vector2)\n",
    "        dot_product = np.dot(unit_vector1, unit_vector2)\n",
    "        angle = np.arccos(dot_product)\n",
    "        return np.degrees(angle)\n",
    "\n",
    "    significant_points = [contour[0]]\n",
    "    for i in range(1, len(contour) - 1):\n",
    "        angle = angle_between(contour[i - 1][0], contour[i][0], contour[i + 1][0])\n",
    "        if angle > angle_threshold:\n",
    "            significant_points.append(contour[i])\n",
    "    significant_points.append(contour[-1])\n",
    "    return np.array(significant_points)\n",
    "\n",
    "def convert_and_save_dataset(src_dir, dest_dir, val_ratio=0.1, img_dims=(640, 640)):\n",
    "    \"\"\"\n",
    "    Process datasets, resize images and masks, and convert masks to YOLO format.\n",
    "    \"\"\"\n",
    "    subsets = ['train', 'test']\n",
    "    all_images = []\n",
    "\n",
    "    for subset in subsets:\n",
    "        images_dir = src_dir / subset / 'images'\n",
    "        labels_dir = src_dir / subset / 'labels'\n",
    "        dest_images_dir = dest_dir / subset / 'images'\n",
    "        dest_labels_dir = dest_dir / subset / 'labels'\n",
    "        \n",
    "        dest_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dest_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for image_path in images_dir.glob(\"*.png\"):\n",
    "            # Resize and save image\n",
    "            dest_image_path = dest_images_dir / image_path.name\n",
    "            resize_and_save_image(image_path, dest_image_path, img_dims)\n",
    "\n",
    "            # Process and convert mask\n",
    "            mask_name = image_path.name.replace(\"flair\", \"consensus\")\n",
    "            mask_path = labels_dir / mask_name\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "            mask_resized = cv2.resize(mask, img_dims)\n",
    "            contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            yolo_annotation_file = dest_labels_dir / mask_name.replace('consensus', 'flair').replace('.png', '.txt')\n",
    "            with open(yolo_annotation_file, 'w') as file:\n",
    "                for contour in contours:\n",
    "                    significant_points = find_significant_points(contour)\n",
    "                    raveled_points = significant_points.reshape(-1, 2)\n",
    "                    rel_points = raveled_points / np.array(img_dims)\n",
    "                    flat_points = rel_points.flatten()\n",
    "                    yolo_format_str = \"1 \" + \" \".join(map(str, flat_points))\n",
    "                    file.write(yolo_format_str + '\\n')\n",
    "            \n",
    "            if subset == 'train':\n",
    "                all_images.append(dest_image_path)\n",
    "\n",
    "    # Create validation set\n",
    "    val_images = random.sample(all_images, int(len(all_images) * val_ratio))\n",
    "    for image_path in val_images:\n",
    "        dest_val_image_path = dest_dir / 'val' / 'images' / image_path.name\n",
    "        dest_val_label_path = dest_dir / 'val' / 'labels' / image_path.name.replace('.png', '.txt')\n",
    "\n",
    "        dest_val_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        dest_val_label_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        image_path.rename(dest_val_image_path)\n",
    "        (dest_dir / 'train' / 'labels' / image_path.name.replace('.png', '.txt')).rename(dest_val_label_path)\n",
    "\n",
    "# Define source and destination directories\n",
    "src_dir = Path(\"C:/Users/zhuyi/Desktop/CREATIS/UNet_YOLO/MSLS-YOLOv8/UNet/data\")\n",
    "dest_dir = Path(\"C:/Users/zhuyi/Desktop/CREATIS/UNet_YOLO/MSLS-YOLOv8/YOLOv8/datasets\")\n",
    "\n",
    "# Convert and save datasets\n",
    "convert_and_save_dataset(src_dir, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# import random\n",
    "# import os\n",
    "# from shutil import copy2, rmtree\n",
    "\n",
    "# def resize_and_save_image(image_path, dest_path, scale_dims=(640, 640)):\n",
    "#     image = cv2.imread(str(image_path))\n",
    "#     image_resized = cv2.resize(image, scale_dims)\n",
    "#     cv2.imwrite(str(dest_path), image_resized)\n",
    "\n",
    "# def find_significant_points(contour, angle_threshold=30):\n",
    "#     def angle_between(p1, p2, p3):\n",
    "#         vector1 = p2 - p1\n",
    "#         vector2 = p3 - p2\n",
    "#         unit_vector1 = vector1 / np.linalg.norm(vector1)\n",
    "#         unit_vector2 = vector2 / np.linalg.norm(vector2)\n",
    "#         dot_product = np.dot(unit_vector1, unit_vector2)\n",
    "#         angle = np.arccos(dot_product)\n",
    "#         return np.degrees(angle)\n",
    "\n",
    "#     significant_points = [contour[0]]\n",
    "#     for i in range(1, len(contour) - 1):\n",
    "#         angle = angle_between(contour[i - 1][0], contour[i][0], contour[i + 1][0])\n",
    "#         if angle > angle_threshold:\n",
    "#             significant_points.append(contour[i])\n",
    "#     significant_points.append(contour[-1])\n",
    "#     return np.array(significant_points)\n",
    "\n",
    "# def convert_and_save_dataset(src_dir, dest_dir, val_ratio=0.1, img_dims=(640, 640)):\n",
    "#     subsets = ['train', 'test']\n",
    "#     all_images = []\n",
    "\n",
    "#     for subset in subsets:\n",
    "#         images_dir = src_dir / subset / 'images'\n",
    "#         labels_dir = src_dir / subset / 'labels'\n",
    "#         dest_images_dir = dest_dir / subset / 'images'\n",
    "#         dest_labels_dir = dest_dir / subset / 'labels'\n",
    "        \n",
    "#         dest_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "#         dest_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "#         for image_path in images_dir.glob(\"*.png\"):\n",
    "#             dest_image_path = dest_images_dir / image_path.name\n",
    "#             resize_and_save_image(image_path, dest_image_path, img_dims)\n",
    "\n",
    "#             mask_name = image_path.name.replace(\"flair\", \"consensus\")\n",
    "#             mask_path = labels_dir / mask_name\n",
    "#             mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "#             mask_resized = cv2.resize(mask, img_dims)\n",
    "#             contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "#             yolo_annotation_file = dest_labels_dir / mask_name.replace('.png', '.txt')\n",
    "#             with open(yolo_annotation_file, 'w') as file:\n",
    "#                 for contour in contours:\n",
    "#                     significant_points = find_significant_points(contour)\n",
    "#                     raveled_points = significant_points.reshape(-1, 2)\n",
    "#                     rel_points = raveled_points / np.array(img_dims)\n",
    "#                     flat_points = rel_points.flatten()\n",
    "#                     yolo_format_str = \"1 \" + \" \".join(map(str, flat_points))\n",
    "#                     file.write(yolo_format_str + '\\n')\n",
    "\n",
    "#             if subset == 'train':\n",
    "#                 all_images.append(dest_image_path)\n",
    "\n",
    "#     val_images = random.sample(all_images, int(len(all_images) * val_ratio))\n",
    "#     for image_path in val_images:\n",
    "#         dest_val_image_path = dest_dir / 'val' / 'images' / image_path.name\n",
    "#         dest_val_label_path = dest_dir / 'val' / 'labels' / image_path.name.replace('flair', 'consensus').replace('.png', '.txt')\n",
    "\n",
    "#         dest_val_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         dest_val_label_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         image_path.rename(dest_val_image_path)\n",
    "#         (dest_dir / 'train' / 'labels' / image_path.name.replace('flair', 'consensus').replace('.png', '.txt')).rename(dest_val_label_path)\n",
    "\n",
    "#     # Remove images and annotations with no tumors (empty annotations)\n",
    "#     for subset in ['train', 'val']:\n",
    "#         labels_dir = dest_dir / subset / 'labels'\n",
    "#         images_dir = dest_dir / subset / 'images'\n",
    "#         for label_file in labels_dir.glob(\"*.txt\"):\n",
    "#             if os.path.getsize(label_file) == 0:  # Check if file is empty\n",
    "#                 os.remove(label_file)  # Remove the empty label file\n",
    "#                 corresponding_img_file = images_dir / label_file.name.replace('consensus', 'flair').replace('.txt', '.png')\n",
    "#                 if corresponding_img_file.exists():\n",
    "#                     os.remove(corresponding_img_file)  # Remove the corresponding image file\n",
    "\n",
    "# # Define source and destination directories\n",
    "# src_dir = Path(\"C:/Users/zhuyi/Desktop/CREATIS/UNet_YOLO/MSLS-YOLOv8/UNet/data\")\n",
    "# dest_dir = Path(\"C:/Users/zhuyi/Desktop/CREATIS/UNet_YOLO/MSLS-YOLOv8/YOLOv8/datasets\")\n",
    "\n",
    "# # Convert and save datasets\n",
    "# convert_and_save_dataset(src_dir, dest_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
